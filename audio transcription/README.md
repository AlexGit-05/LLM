## Audio/Video to text
This Python script performs automated audio transcription with speaker recognition (diarization). It takes an audio file as input and processes it in two main steps: first, it uses the PyAnnote Audio model to identify and separate different speakers in the recording, then it employs OpenAI's Whisper large model to transcribe what each speaker said. The script generates a text output file that includes timestamps, speaker labels, and the transcribed speech for each segment. It supports GPU acceleration through CUDA and includes features like environment setup, Hugging Face authentication, and temporary file management for processing the audio segments.
